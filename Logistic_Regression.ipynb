{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3a0867f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 횟수 200, 정인식률: 85.253%\n",
      "학습 횟수 300, 정인식률: 89.674%\n",
      "학습 횟수 400, 정인식률: 92.216%\n",
      "학습 횟수 500, 정인식률: 93.540%\n",
      "학습 횟수 600, 정인식률: 94.625%\n",
      "학습 횟수 700, 정인식률: 94.731%\n",
      "학습 횟수 800, 정인식률: 94.996%\n",
      "학습 횟수 900, 정인식률: 95.367%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.utils import shuffle \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "# <하이퍼파라미터 및 데이터 정제 코드>\n",
    "iteration = 1000 # 반복 횟수 설정\n",
    "learning_rate = 0.1 # 학습률 설정\n",
    "\n",
    "data = pd.read_csv(\"C:\\weatherReports.csv\") # CSV 파일 로드\n",
    "data = data[['event_narrative', 'event_type']] # 필요한 컬럼 선택\n",
    "data = data.dropna(axis=0) # 결측치 제거\n",
    "\n",
    "# <'Thunderstorm Wind'와 'Hail'을 필터링.>\n",
    "thunder_data = data[data['event_type'] == 'Thunderstorm Wind']\n",
    "hail_data = data[data['event_type'] == 'Hail']\n",
    "\n",
    "data = pd.concat([thunder_data, hail_data]) # 두 데이터 병합\n",
    "data = shuffle(data) # 데이터 셔플\n",
    "\n",
    "# <라벨링 (Thunderstorm Wind는 0, Hail은 1로 변환)>\n",
    "data['event_type'].replace('Thunderstorm Wind', 0, inplace = True)\n",
    "data['event_type'].replace('Hail', 1, inplace = True)\n",
    "\n",
    "sentences = [] # 문장을 저장할 리스트 생성\n",
    "for sentence in data['event_narrative']:\n",
    "    sentences.append(sentence) # 문장을 리스트에 추가\n",
    "    \n",
    "cv = CountVectorizer(stop_words = \"english\") # CountVectorizer 객체 생성, 영어 불용어 제거\n",
    "cv.fit(sentences) # BoW 설계를 위한 학습\n",
    "\n",
    "vectors = cv.transform(sentences).toarray() # 문장을 벡터로 변환\n",
    "label = data['event_type'].to_numpy() # 라벨을 numpy 배열로 변환\n",
    "\n",
    "# <가설, 정확도 함수, 데이터셋 분리>\n",
    "train_rate = 0.7 # 훈련 데이터 비율\n",
    "train = int(0.7 * len(data)) # 훈련 데이터 수 계산\n",
    "# <훈련 데이터와 테스트 데이터 분리>\n",
    "train_x, test_x = vectors[:train], vectors[train:]\n",
    "train_y, test_y = label[:train], label[train:]\n",
    "theta = np.random.rand(vectors[0].shape[0], 1) # 가중치 초기화\n",
    "\n",
    "# <가설 함수 정의>\n",
    "def hypothesis(x):\n",
    "    x = x.reshape(9302, 1) # 입력 벡터 재구성\n",
    "    res = (1 / (1 + np.exp(-(np.dot(theta.T, x))))) # 시그모이드 함수 적용\n",
    "    return res.item()\n",
    "\n",
    "# <정확도 계산 함수 정의>\n",
    "def accuracy():\n",
    "    cnt = 0\n",
    "    for i in range(len(test_x)):\n",
    "        res = 1 if hypothesis(test_x[i]) > 0.5 else 0 # 예측 값 계산\n",
    "        if res == test_y[i]: cnt += 1 # 예측이 정확하면 카운트 증가\n",
    "    return cnt / len(test_x) # 정확도 계산\n",
    "\n",
    "# <세타 갱신 코드>\n",
    "prev_accuracy = 0.0 # 이전 정확도 저장\n",
    "for i in range(iteration):\n",
    "    for j in range(theta.shape[0]):\n",
    "        temp = train_y[i] - hypothesis(train_x[i])\n",
    "        theta[j] += (learning_rate * temp.item() * train_x[i, j]) # 가중치 업데이트\n",
    "    if i % 100 == 0 and i > 100: # 100번째 반복마다 정확도 체크\n",
    "        current_accuracy = accuracy()\n",
    "        \n",
    "        if current_accuracy > prev_accuracy: # 이전 정확도보다 높을 때만 출력\n",
    "            print(f\"학습 횟수 {i}, 정인식률: {current_accuracy * 100:.3f}%\")\n",
    "            prev_accuracy = current_accuracy\n",
    "        else: # 현재 정확도가 이전 정확도보다 낮을 경우, 이전의 최고 정확도를 유지\n",
    "            prev_accuracy = max(prev_accuracy, current_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
